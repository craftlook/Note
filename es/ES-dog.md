## ES 集群工作中的使用场景

#### 背景

&ensp;&ensp;传统的电商系统中的两大用户体系C端用户和B端用户（商家）。C端订单系统面向用户提供订单业务能力，商家订单系统面向商家用户提供订单查询、操作等业务能力。在具体的生产使用场景中，C端用户订单生产后对于其主要的关注点就是订单状态以及售后，所以C用户无论APP、PC端对订单的查询主要的条件就是状态、时间、订单号。对于商家端用户由于对订单会有许多业务诉求，需要依据复杂的业务字段来进行查询订单。  

&ensp;&ensp;商家端相较于C端用户的对订单的查询使用方式相对更复杂。由于C端的请求量巨大，查询条件单一，可以通过数据库和集群缓存的方式来满足C端订单的查询。而B端的请求量量级与C端相比较小（请求量依旧客观），查询业务复杂条件较多。既要满足对复杂条件查询又要支持前端大量请求，通过数据库和缓存的传统结构，业务实现复杂切困难，时间和维护的成本与收益不成正比。在工作中，我们通过使用ES存储来进行对业务的支持。

#### 查询架构

![avatar](https://github.com/craftlook/Note/blob/master/image/es/ES-oldstructure.png)

&ensp;&ensp;图中是生产中数据流转的情况。订单数据通过上游的数据下发到生产系统后，系统对数据进行入数据库，数据库发送binlog消息，通过对binlog消息的转换存入ES集群（ES主/备集群 主集群数据节点50台、网关节点5台）。外部的查询通过代理层从ES集群查询订单数据。

&ensp;&ensp;上图是ES集群对商家订单支持的最初的方案。随着数量流量的增多，ES索引越来越大单一索引达到了200亿的文档数，ES对外部的查询支持接口性能出现下降，整体集群CPU也出现频繁的抖动。简单的主/备集群的架构显然无法支持线上的流量。又由于商家订单的路由规则是商家id，会出现大商家的数据倾斜和热点问题对于集群的查询和写入都会出现热点性能的影响。

![avatar](https://github.com/craftlook/Note/blob/master/image/es/ES-nowstructure.png)

&ensp;&ensp;图中ES集群的结构是改造以后的情况。

&ensp;&ensp; **热点数据隔离**：对于KA商家进行索引分离增加KA索引，KA商家与普通商家在索引维度的进行数据隔离。通过索引分离减少遍历文档的总量，在查询性能上大商家和普通商家的性能明显提升。

&ensp;&ensp;**冷热数据分离**：针对与商家主要日常处理的是近三个月的订单，其主要的请求查询在近3个月的订单，三个月后的订单到近半年的时间范围次之。半年之前订单的查询量主要集中在商家的报表导出查询分析数据上。经过以上的请求分析，首先对冷数据进行数据的归档以年为维度进行索引创建。历史的数据和对历史的操作都会在归档集群中进行保存、操作。主集群、备集群主要保留近半年的数据。ES代理应用中会根据请求判断本次请求的数据范围，依据范围确定是通过哪个集群获取数据。对从主集群、归档集群获取的数据，代理应用还会进行汇总返回。
![avatar](https://github.com/craftlook/Note/blob/master/image/es/ES-furstructure.png)


